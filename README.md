# MountainCar_QLearning
Using QLearning to solve the Open AI Gym's Mountain Car Environment

![Demo](https://github.com/namantuli18/MountainCar_QLearning/blob/master/imgs/demo.PNG)
## First Ascent
*When the first ascent happens i.e. in relatively simpler terms, new_state[0]>=env.goal_position happens:*

![1st](https://github.com/namantuli18/MountainCar_QLearning/blob/master/imgs/1st%20ascent.PNG)
## Rapid Ascent
But it's on the users capability to judge the fact that once a successful ascent happens,the ability of the agent to reproduce such magnificent{xD} results drastically increases.

![rapid](https://github.com/namantuli18/MountainCar_QLearning/blob/master/imgs/rapid.PNG)
## Rendering on OpenAI Gym
When we do an env.render() on a successful episode,the result looks like:

![success](https://github.com/namantuli18/MountainCar_QLearning/blob/master/imgs/success.PNG)

## Stats
*When we plot the values of max,min and avg score for every episode,the plot looks like:*
![stats](https://github.com/namantuli18/MountainCar_QLearning/blob/master/imgs/stats.PNG)
